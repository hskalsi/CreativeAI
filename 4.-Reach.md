## Sections

- [Description] (#reach-description)
- [Structure] (#reach-structure)
- [Getting New Music (Optional)] (#getting-new-music-optional)
- [Explanation of Required Functions to Implement] (#explanation-of-required-functions-to-implement)
  - [getNextNote](#getnextnote)
  - [trainMusicModels](#trainmusicmodels)
  - [generateMusicalSentence](#generatemusicalsentence)
  - [runMusicGenerator](#runmusicgenerator)
- [Explanation of Functions Given to You] (#explanation-of-given-functions)
- [Explanation of Required Graphical Component] (#explanation-of-graphical-component)
- [How to Make Your Final Product Unique](#how-to-make-your-final-product-unique)
- [How to Test Your Program] (#how-to-test-your-program)
- [How to Run Your Program to Generate Music] (#how-to-run-your-program-to-generate-music)
- [Turning in Your Reach](#turning-in-your-reach)

## Reach Description

For the core, you implemented a program to create a model of a music artist's lyrics. For the reach, you will do much of the same, but use pre-processed music data in text form and a cool Python program called [PySynth](./Concepts#how-pysynth-works) to create actual randomly generated music in the form of .wav files, which can be played with software like iTunes or Windows Media Player.

You are also required to include a graphical component to your reach ([see description for more details](#explanation-of-graphical-component)).

The great thing about the reach is that you get to be creative with your final output. Therefore, you only have to implement a few required functions and features, and beyond that you can add new functions to [make your final product unique](#how-to-make-your-final-product-unique).

You should be familiar with the [basics of PySynth](./Concepts#how-pysynth-works) before attempting to implement the reach.

As with the core, the _required functions_ of the reach do not require you to include any external libraries beyond what has already been included for you. Use of any other external libraries is prohibited on this part of the project. _However_, on the creative part of the reach, and on the graphical portion, you are free to use whatever tools you want.

## Reach Structure

All of the reach functions that you are required to implement are in the same files that you used for the core. You will implement [```getNextNote```](#getnextnote) in ```nGramModel.py```. In ```generate.py```, you will implement [```trainMusicModels```](#trainmusicmodels), [```generateMusicalSentence```](#generatemusicalsentence), and [```runMusicGenerator```](#runmusicgenerator). All of these functions will be similar to functions you wrote in the core.

## Getting New Music (Optional)

If your team chooses not to use the provided music from the Nintendo Gamecube, you will need to either use the ```vgMusicScraper.py``` file to get music data from another video game console, or else find an alternative way to get MIDI files. If you choose the latter option, you will need to consult with a staff member for instructions on how to convert MIDI files to .txt files, since the program takes music data in the form of text.

To get new data for a video game console, run the ```vgMusicScraper.py``` program in the ```data/scrapers``` directory. The program will ask you to input the name of a platform; examples are "gameboy" or "xbox". To see the full list of platforms, take a look at the ```vgMusicPlatforms.txt``` file in the same directory - the platforms are the second column of data in that file. After you type in a valid platform, the program will grab MIDI files from [vgmusic.com](http://www.vgmusic.com) for that platform and call another program to convert those MIDI files into .txt files, saving all those files in the ```data/midi/<platform>``` directory. Don't be alarmed if this takes a little while, depending on the number of MIDI files it finds to download.

## Explanation of Required Functions To Implement

### ```getNextNote```

This function is similar to [```getNextToken```](./3.-Core#getnexttoken) from the core, but it has some added constraints. You will notice that this function takes an extra parameter that ```getNextToken``` did not take, which is a list called ```possiblePitches```. This list is a set of music notes formally called a *key signature*, which tells you which notes are allowed in a section or piece of music. In this function, you are only allowed to return a PySynth tuple whose pitch falls in the ```possiblePitches``` list. 

Here is how this function will work:

1. Obtain a dictionary of all possible candidate notes and their respective counts using the ```getCandidateDictionary``` function you wrote in the core. For the sake of this example, let's call this first dictionary ```allCandidates```.

2. Make a new empty dictionary, which will hold the notes from the candidate dictionary that are *also* found in the ```possiblePitches``` list. Let's call this second dictionary ```constrainedCandidates```.

3. Walk through the ```allCandidates``` dictionary and examine each key. If a key in ```allCandidates``` satisfies one of the two following criteria, then add that key and its respective value to the ```constrainedCandidates``` dictionary:

  a. The key is a PySynth tuple whose pitch, excluding the octave number at the end, can be found in the ```possiblePitches``` list. For example, say your ```possiblePitches``` list contains the string ```'c#'```, and the tuple you are currently looking at is ```('c#6', 4)```. Then this tuple should be added to ```constrainedCandidates``` because ```'c#'``` is part of the tuple's pitch. Note that this will require a bit of string parsing because PySynth tuples contain an octave number as part of the pitch string, but the pitches in the ```possiblePitches``` list do not contain octave numbers.

  b. The key is a string whose value is *$:::$*, which is the special ending symbol.

4. After you are done walking through the ```allCandidates``` dictionary, you should do one of two things:

  a. If ```constrainedCandidates``` is not empty, pass it to the ```weightedChoice``` function and return the value that ```weightedChoice``` returns, just like you did in the core. 

  b. Else, return a PySynth tuple, where the first item in the tuple is a random pitch from ```possiblePitches``` plus the string ```'4'``` appended to the end of the pitch, and the second item in the tuple is a random number from the ```NOTE_DURATIONS``` list, which is defined in ```data/musicData.py``` and imported into ```nGramModel.py``` for you to use. To pick a random item from a list, you can use Python's ```random.choice``` function.

### ```trainMusicModels```

This function is very similar to [```trainLyricsModels```](./3.-Core#trainlyricsmodels) from the core. The only difference is that it calls the ```loadMusic``` function from the DataLoader class instead of the ```loadLyrics``` function, loads its data from a different directory, and stores the loaded data into ```dataLoader.songs``` instead of ```dataLoader.lyrics```. 

### ```generateMusicalSentence```

This function is very similar to [```generateSentence```](./3.-Core#generatesentence) from the core. The only difference is that it calls the [```getNextNote```](#getnextnote) function for its language models instead of the ```getNextToken``` function from the core.

### ```runMusicGenerator```

This function is required, but there are only a few things that this function *must* do: 

1. It must pick a key signature for the song to be generated by randomly choosing a key from the ```KEY_SIGNATURES``` dictionary, which is defined in ```data/musicData.py```. This effectively gives you the list of notes, ```possiblePitches```, to use in generating your music. So for example, say you randomly chose "c major" as the key for the song, then ```KEY_SIGNATURES['c major']``` would be your ```possiblePitches``` list. To randomly choose a key from the dictionary, you can use Python's ```random.choice``` function on the list of keys in the dictionary.

2. It must call ```generateMusicalSentence```, since this is the function that ultimately creates lines of music. When calling ```generateMusicalSentence```, you should pass the function the list of pitches that corresponds to the key signature that you randomly chose in step 1. Also note that you can pick the value of ```desiredLength``` when generating your musical sentences, as you did in the core. With a smaller value of ```desiredLength``` you can create short lines of music and string them together later in [```runMusicGenerator```](#runmusicgenerator), or with a larger value of ```desiredLength``` you can create an entire song in this function.

3. It must ultimately store the generated song as a list of PySynth tuples.

4. It must call ```pysynth.make_wav(tuplesList, fn=songName)``` after your list of PySynth tuples is generated in order to actually make the .wav file. The ```tuplesList``` parameter will be the list of PySynth tuples that comprise your song. The ```fn=songName``` part tells PySynth what to name the .wav output file, which will be stored in the ```wav/``` directory when PySynth is finished making your song. 

Beyond these four requirements, how ```runMusicGenerator``` is implemented is ultimately up to you because you get to decide the specifics of how your music will be structured. That being said, there are certain guidelines that should be followed. For more information and more ideas on how to make your music unique, see [this section](#how-to-make-your-music-unique).

## Explanation of Given Functions

See the [Explanation of Given Functions](./3.-Core#explanation-of-given-functions) section from the core.

## Explanation of Graphical Component

You are also required to have a graphical or visual component to your reach for the Showcase presentation. This can be done programmatically (with a Python library, for instance) or non-programmatically (with a graphical tool). Here a few suggestions for graphical tools that we find interesting, although you are free to use a tool not on this list:
- [Windows Media Player Visualizations](https://support.microsoft.com/en-us/help/17878/visualizations-for-windows-media-player)
- [iTunes Visualizer](http://www.macworld.com/article/3074173/streaming-services/how-to-trip-out-with-the-itunes-visualizer.html)
- [SoundSpectrum](https://www.soundspectrum.com/) (**Note:** there are both free trial and paid versions of this product. You are not required to buy anything for this project)
- [Python ```wave``` and ```matplotlib``` libraries (see link for example)](http://stackoverflow.com/questions/18625085/how-to-plot-a-wav-file)
- [Friture](http://friture.org/)

## How to Make Your Final Product Unique

For the core, we had you follow a strict format for how you ultimately outputted your generated lyrics. However, for the reach, you get to be creative. Therefore, you can modify any part of the project that you want, or write new functions of your own, to achieve whatever ideas you have in mind. Here are some ideas for making your final product unique. Note that some of these alone are not enough to satisfy the creativity requirement for the reach. For this reason, we ask that you are detailed in your reach proposal so that we can notify you if it needs adjustment. Furthermore, this is not a comprehensive list of reach possibilities - feel free to think outside of the box and have fun with it! If you have any questions, please contact the project staff. 

- One thing that we recommend you do to make your music sound more cohesive is make your generated songs start with, and end with, the first note in the ```possiblePitches``` list (the key signature you randomly chose in ```runMusicGenerator```). This note in music is called the *tonic*, and starting and ending on that note makes a piece of music sound more cohesive to the listener. To do this, you can simply make a PySynth tuple with the first value being the first note in your ```possiblePitches``` list, and the second value being a random duration chosen from the ```NOTE_DURATIONS``` list (like what you did for ```getNextNote```).
- You could make songs with different sections in different key signatures.
- Try playing around with structure (think of songs you know - how are they structured? What makes them unique?)
- One thing that is missing from the music data is rests, or pauses in the music. PySynth supports rests (see the [section on PySynth](./Concepts#how-pysynth-works) for more detail), which means that after you are done generating a song, you can go back and insert rests into the song
- You could randomly generate titles for songs using the lyric data from the core.
- You could also randomly generate titles for songs using the actual titles of the songs stored in the music data folder.
- You could match your generated lyrics to your generated music, so you're creating an entire "song".
- Going back to the lyrics part of the project, you could download lyrics for multiple artists and create lyric mashups (this can be quite funny given the artists that you choose).
- PySynth provides a function called ```mix_files``` to mix two .wav files together so that you can have more than one note playing at the same time. To call ```mix_files```, you do something like this, where ```wavFile1``` and ```wavFile2``` are the files you want to combine, and ```outputWavFile``` is the file that will contain the mixed music:

```python
pysynth.mix_files(wavFile1, wavFile2, outputWavFile)
```
Basically, think about your favorite songs or pieces of music, and think about the things that make them unique lyrically or musically. Then, think about how you can represent those characteristics using the Python tools and constructs you know. 

**A few important notes**:

- For the "creative" part of the reach, you don't have to focus on making your music better if your group only wants to work with the lyrics part of the project.

- For the reach, you are allowed to change any of the functions we implemented for you: i.e. ```main```, ```getUserInput```, and so on. However, **make sure not to change the functionality of ```getNextNote```, ```trainMusicModels```, or ```generateMusicalSentence```**. This is because we plan on automatically grading these three functions, and if you change what they do then you will fail our tests. If you want to change the way your program gets a note or generates a musical sentence, just write new functions to do so.

- **IMPORTANT: you are certainly allowed to play around with your music using software like Garage Band and the likes. However, because doing so usually doesn't involve writing code or conceptual computer science, we won't award creative reach points for music improvements using such software. Feel free to use them if you want to improve your final output, but also make sure to do things that involve programming!**

## How to Test Your Program

See the section on [How to Test Your Program](./3.-Core#how-to-test-your-program) from the core.

## How to Run Your Program to Generate Music

If you are using PyCharm, open ```generate.py``` and click "Run..."  If you are working in the command line, navigate to the root Creative AI repository and run this command:

```
python generate.py
```

as you did in the core. In either case, after PySynth creates the final .wav file, you should find that file in the ```wav/``` directory, where you can open and play it.

## Turning in Your Reach

When you submit your final reach product via GitHub, please include a README.txt file in the root repository. The README.txt file **must** include instructions on how to run your program and any other information we would need about how it works (i.e. Windows vs Mac differences, environment variables, etc.) If we cannot run your program, grading will be much more difficult for us, and may even result in a zero for this portion of your project. See [the Grading section](./5.-Grading-Policy-and-Dates) for more info.