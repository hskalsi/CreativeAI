# Overview

Now that you've implemented the core, you can build from it to create more interesting projects. You now have a project that generates music and lyrics based on an artist's repertoire. You will build on that core to both create better models and new ways of showing your models.

The Reach, then, has two components: a Visual Component and a Data Component. **You must complete one Visual Reach and one Data Reach.** We have provided four options, but how you implement them is entirely up to your interests. There is no autograder for the Reach --  we will grade everything by hand. So feel free to explore ideas that interest you and shape your project the way you want to shape it. With that in mind, you may use any tools or external libraries you would like. Outside tools are allowed and encouraged. As long as you complete one Visual Component and one Data Component, your Reach may use any other tools you would like.

# 1. Visual Component

You must complete one of the following Visual Components. The language models you have built are very powerful, but right now they just produce text and midi files. We want you to use one of these reaches to visualize your projects so that users can *see* the data you've produced.

## 1.1 Twitterbot

For this component, you will integrate your learning model with twitter. This reach will give you experience working with twitter's API and applying your model to other kinds of data. We recommend the python library **tweepy** (though you may use others). To begin, you'll need to download the tweepy module:

```pip install tweepy```

You will also need to [register a twitter account](https://twitter.com/signup/). Feel free to customize your account however you like, but **remember to keep it eecs183-appropriate.** You will need to [generate an access token](https://themepacific.com/how-to-generate-api-key-consumer-token-access-key-for-twitter-oauth/994/) (This is what will allow your project code to be authorized to use twitter's features.) Once you've done that, you can begin working with your twitter bot. A good explanation of how to get started can be found [here](http://pythoncentral.io/introduction-to-tweepy-twitter-for-python/).

Once you get your twitter bot working, you can extend it in whatever ways interest you. You could, for instance, train your bot on a public figure's timeline and generate new tweets for that figure. You could turn your twitter bot into a public interface for your lyrics generation. Pick an option that interests you and develop it.

Note: Please keep your twitter bot eecs183-appropriate. Also note that, when we go to grade your bot, we will need need your authentication keys in order to test its capabilities. **Please include all access tokens when you submit your final project. Failure to run your code will result in its not being graded.**

## 1.2 Data Visualization

For this component, you will be creating graphs and visualizations of the data you've generated with your model. This will give you experience working with plotting and graphing. We recommend using one of the following libraries, but you may use any equivalents you can find:

[**matplotlob**](http://matplotlib.org) -- a very common python library used for creating graphs and tables

[**plot.ly**](https://plot.ly) -- less common than matplotlib, not all features free, but more visually dynamic

[**wordcloud**](http://amueller.github.io/word_cloud/) -- used for creating wordclouds out of text data

To install your library, you can run one of the following commands from a terminal (make sure you have installed pip first):

```pip install matplotlib```

```pip install plotly```

```pip install wordcloud```

You will first want to familiarize yourselves with how your library works. Click on the tutorials linked in the list above. Once you have the capability to create graphs or wordclouds, you will need to figure out some way of representing the data you've generated. For instance, you could use the music scraper to download different artists and then use wordcloud to compare how different artists tend to use different words. You could graph the prevalence of different notes generated in different genres of music. You could compare the data your model generates with the corpus for a particular artist.

Pick something that sounds interesting to you and develop it.


# 2. Data Component

You must complete one of the following Data Components. These will extend your models so that the data you produce begins to sound like real music or real song lyrics. 

## 2.1 Grammatical Lyrics

This component will work on the quality of your lyric generation. What you developed in the core generates phrases, but they often don't sound like real English lyrics. We can use the python library **nltk** to provide rules to modify our language models.

To start, you will need to [download nltk](http://www.nltk.org/install.html). After downloading, you will need to [download a grammar](http://www.nltk.org/data.html) for the lyrics you want to generate. This will probably be the English grammar, though you may use other grammars if you want to extend your model to lyrics from other languages. **Please specify which grammars your program requires when you submit. If we do not know which grammars we need to download we may be unable to grade your project.**

At a simple level, nltk works by tagging words with their parts of speech. By checking the parts of speech of words as you generate them, you can construct sentences that make grammatical sense. But nltk offers many more capabilities; you will want to read some of the nltk documentation. You could, for instance, use a non-English grammar to develop your model with song lyrics from another language. You could use nltk's sentiment library to create positive or negative songs. As always, pick something that interests you and run with it.

## 2.2 Musical Harmony

The last component won't involve any new libraries, but will use more of ```pysynth```'s functionalities. You will be learning about music and harmonic theories to generate songs more pleasing to the ear. While randomly-generated songs can be fun, they often don't sound anything like real music. But by mixing in other song layers, we can still use random-generation to create more complex songs that are fun to listen to.

There are a few ways to achieve this. You can start by creating a backbeat, a repetition of notes that lasts for the duration of the song. By picking a few random notes and alternating between them, you can create one layer of a more complex song.

You can also create a pentatonic progression -- a sequence of notes that moves through a chord progression in a loop throughout the rest of the song. Just by creating this layer and adding it to your songs the music you produce will be more complex.

You can also affect the quality of the random notes you generate. You can attempt to fit these into some musical pattern by not repeating the same note too many times or by producing longer patterns of notes that then get fit together in your song.

In order to do this, you will need to figure out how to merge song files together using pysynth. Do not just generate separate layers and perform them together; **if you don't create final, finished songs with your program, we will be unable to listen to and grade your project.**

# Submission

We will grade the last submission to your GitHub team repository before the project deadline. We will ***NOT*** grade earlier submissions, revert to an early commit, or make any changes to your project. We will run your project exactly as they are submitted. If you forget to push changes to your repository before the deadline we will not grade them. 

Please include a file named `README.md` root directory of your repository. The `README.md` file must include a summary of what your reach does and instructions on how to run your program. If your project uses additional external libraries you must specify them here so we know to download them. If your project only runs on Windows or Mac, please let us know so we will grade it on the proper machine. Except for external libraries, if your code does not run when we pull your repository, you will get a 0. See the Grading section for more info.

Remember, this is now your project. There is no autograder. We want you to be creative with your final project and shape your reach in a way that's interesting to *you*. You must pick one Data and one Visual option, but these options are guidelines only. 

**Notes:**

- You are allowed to change any of the functions we implemented for you: i.e. ```main```, ```getUserInput```, and so on. We've already autograded your core and there is no autograder for the reach.

- You are certainly allowed to play around with your music using software like Garage Band and the likes. However, because doing so usually doesn't involve writing code or conceptual computer science, we won't award creative reach points for music improvements using such software. Do feel free to use them if you want to improve your final output for the showcase.

- Unless specified otherwise in your ```README.md```, this is how we will run your program: ```python generate.py```